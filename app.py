import spaces
import gradio as gr
import torch
import librosa
import numpy as np
from inference import inference
from huggingface_hub import hf_hub_download
from pathlib import Path

def download_models_from_hub():
    """
    Download model checkpoints from Hugging Face Model Hub
    """
    model_dir = Path("checkpoints")
    model_dir.mkdir(exist_ok=True)
    
    models = {
        "main": "EmbeddingModel_MERT_768-epoch=0073-val_loss=0.1058-val_acc=0.9585-val_f1=0.9366-val_precision=0.9936-val_recall=0.8857.ckpt",
        "backup": "step=007000-val_loss=0.1831-val_acc=0.9278.ckpt"
    }
    
    downloaded_models = {}
    
    for model_name, filename in models.items():
        local_path = model_dir / filename
        
        if not local_path.exists():
            print(f"üì• Downloading {model_name} model from Hugging Face Hub...")
            model_path = hf_hub_download(
                repo_id="mippia/FST-checkpoints",
                filename=filename,
                local_dir=str(model_dir),
                local_dir_use_symlinks=False
            )
            print(f"‚úÖ {model_name} model downloaded successfully!")
            downloaded_models[model_name] = str(local_path)
        else:
            print(f"‚úÖ {model_name} model already exists locally")
            downloaded_models[model_name] = str(local_path)
    
    return downloaded_models

@spaces.GPU
def detect_ai_audio(audio_file):
    """
    Detect whether the uploaded audio file was generated by AI
    and format the result based on the standardized output.
    """
    if audio_file is None:
        return "<div>‚ö†Ô∏è Please upload an audio file.</div>"

    try:
        result = inference(audio_file)  # {'prediction': 'Fake', 'confidence': '93.80', ...}

        prediction = result.get('prediction', 'Unknown')
        confidence = result.get('confidence', '0.00')
        fake_prob = result.get('fake_probability', '0.0')
        real_prob = result.get('real_probability', '0.0')
        raw_output = result.get('raw_output', '')

        formatted_result = f"""
        <div style="text-align: center; padding: 15px; border-radius: 10px; border: 1px solid #ccc;">
            <h2>Prediction: {prediction}</h2>
            <p>Confidence: {confidence}%</p>
            <p>Fake Probability: {float(fake_prob)*100:.2f}%</p>
            <p>Real Probability: {float(real_prob)*100:.2f}%</p>
            <p>Raw Output: {raw_output}</p>
        </div>
        """
        return formatted_result

    except Exception as e:
        return f"<div>Error processing audio: {str(e)}</div>"

# Ïã¨ÌîåÌïòÍ≥† ÍπîÎÅîÌïú CSS
custom_css = """
.gradio-container { background: #f5f5f5 !important; min-height: 100vh; }
.main-container { background: #ffffff !important; border-radius: 15px !important; box-shadow: 0 8px 20px rgba(0,0,0,0.1) !important; margin: 20px auto !important; padding: 30px !important; max-width: 800px; }
h1 { text-align: center !important; font-size: 2.5em !important; font-weight: 700 !important; margin-bottom: 15px !important; color: #333 !important; }
.gradio-markdown p { text-align: center !important; font-size: 1.1em !important; color: #555 !important; margin-bottom: 20px !important; }
.upload-container { background: #f0f0f0 !important; border-radius: 10px !important; padding: 15px !important; border: 1px solid #ccc !important; margin-bottom: 20px !important; }
.output-container { background: #fafafa !important; border-radius: 10px !important; padding: 15px !important; border: 1px solid #ccc !important; min-height: 150px !important; }
.gr-button { background: #667eea !important; color: #fff !important; border: none !important; border-radius: 20px !important; padding: 10px 25px !important; font-weight: 600 !important; transition: all 0.2s ease !important; }
.gr-button:hover { background: #5563c1 !important; transform: translateY(-2px) !important; }
@media (max-width: 768px) {
    h1 { font-size: 2em !important; }
    .main-container { margin: 10px !important; padding: 20px !important; }
}
"""

# Ï¥àÍ∏∞Ìôî
print("üöÄ Starting FST AI Audio Detection App...")
print("üì¶ Initializing models...")
models = download_models_from_hub()
if models.get("main"):
    print("‚úÖ Main model ready for inference")
else:
    print("‚ö†Ô∏è Warning: Main model not available, app may not work properly")

# Gradio Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
demo = gr.Interface(
    fn=detect_ai_audio,
    inputs=gr.Audio(type="filepath", label="Upload Audio File", elem_classes=["upload-container"]),
    outputs=gr.HTML(label="Detection Result", elem_classes=["output-container"]),
    title="Fusion Segment Transformer for AI Generated Music Detection",
    description="""
    <div style="text-align: center; font-size: 1em; color: #555; margin: 20px 0;">
        <p><strong>Fusion Segment Transformer: Bi-directional attention guided fusion network for AI Generated Music Detection</strong></p>
        <p>Authors: Yumin Kim and Seonghyeon Go</p>
        <p>Submitted to ICASSP 2026. Detects AI-generated music by modeling full audio segments with content-structure fusion.</p>
        <p>‚ö†Ô∏è Note: On Zero GPU environment, processing may take ~30 seconds per audio file.</p>
    </div>
    """,
    examples=[],
    css=custom_css,
    theme=gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="purple",
        neutral_hue="gray",
        font=[gr.themes.GoogleFont("Inter"), "Arial", "sans-serif"]
    ),
    elem_classes=["main-container"]
)


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860,  show_api=False, show_error=True)
